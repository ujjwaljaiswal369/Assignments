{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "907c0672-082b-443e-9af1-bd9109bd4e41",
   "metadata": {},
   "source": [
    "## Ensemble Techniques And Its Types-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b16d38e-e336-4d83-b00b-429327245b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q1. What is an ensemble technique in machine learning?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c57be25-267c-4869-885c-81c8e10b8b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans.\n",
    "Ensemble technique in machine learning is technique in which it combines the multiple machine learning models and train \n",
    "the data and aggregate the prediction from base learners through voting classifier. The ensemble technique is helps in \n",
    "improving the model accuracy and performance, especially in case of noisy and complex problems.\n",
    "\n",
    "There are two types of ensemble techniques:\n",
    "    1. Bagging\n",
    "    2. Boosting\n",
    "    \n",
    "1. Bagging : Bagging ensemble technique is a technique which combines the multiple models which called as base learners\n",
    "             and sending the piece of data from dataset to base learners and after the models predict the output in form\n",
    "             of 0 and 1 then it aggregate the ouputs through voting classifier.\n",
    "        \n",
    "2. Boosting : In boosting ensemble technique, it boost the machine learning models by combining the one or more weak \n",
    "              models and prepare a strong prediction model for reducing training errors. Boosting technique have further \n",
    "              also three types Adaboost, Gradient boosting, Xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294877d6-99ce-415a-b34e-b563146cc8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bec63d4-e131-4b6e-bc09-a9f084054010",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q2. Why are ensemble techniques used in machine learning?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bea76fb-af8b-4a5f-b3a2-8a9c113b7755",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans.\n",
    "Ensemble technique is used in machine learning for making model better. For better performance model with good accuracy,\n",
    "we use ensemble techniques because ensemble use multiple machine learning models like Decision tree, Support Vector\n",
    "machine, Naive Bayes,etc. and make base learners and give accurate predictions than a single model prediction. Mostly it\n",
    "use decision tree model in both bagging and boosting techniques.\n",
    "\n",
    "Under the ensemble technique, many types of ensemble techniques such as Random forest classifier, Xg boost, gradient \n",
    "boosting and Adaboost. Ensemble techniques is use bootstrap aggregation and make prediction through using multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d927e3b-93b6-43c9-ad96-6ca0579e0e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293236e8-e9e3-45fd-a271-82589990dd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q3. What is bagging?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a8d5c4-b796-44b7-affe-17052468b4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans. \n",
    "Bagging Ensemble Technique: \n",
    "    \n",
    "Bagging is a type of ensemble technique which are used for making better performance machine learning models. In bagging\n",
    "technique, It combines the multiple machine learning algorithms which is called as base learners in ensemble technique.\n",
    "Then a piece of data from dataset is sending to base learners which make prediction in the form of binary numbers(0 and 1)\n",
    "and it aggregate the outcomes given by base learners through voting classifier method .\n",
    "Voting classifier is a method in which it select those outcomes which number of occurence and priority among all models \n",
    "are high.\n",
    "The process of transferring the data to base learner and happening aggregation is called Bootstrap aggregation.The bagging \n",
    "have one type of algorithms which is Random Forest Classifier and Regressor. \n",
    "\n",
    "The bagging ensemble technique have also out of bag score , Out of bag score mean when the bootstrap aggregation process\n",
    "is happening then some data in training data is remains which are unused and this unused data is trandform in validation\n",
    "data and finding its validation accuracy and that accuracy is called Out of bag score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be239f95-6587-43aa-a042-bdad39f22be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2ac6d4-4fd4-485f-bab1-e4ea08f35cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q4. What is boosting?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a87188d-a01e-4895-a71e-c0c64ef5fc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans.\n",
    "Boosting Ensemble Technique:\n",
    "\n",
    "Boosting ensemble technique is a another type of ensemble technique which are combining the models in squencially one \n",
    "after one and get the strong model which predict the predictions. In another words, there are two types of learners models.\n",
    "One is weak learner model and other is strong learner. In Boosting, it combines the weak learners with their assignments\n",
    "of weight and give a strong learner which give a good prediction.\n",
    "\n",
    "We can understand it in term of confidence also, suppose weak learners have 10,15,30,etc % confidence then from combination\n",
    "of weak learners it confidence also add and form a fully confident strong model predictor. Boosting can use in terms of\n",
    "both classification and regression problem.\n",
    "\n",
    "Following are the algorithms of boosting ensemble technique which is used for boosting the models:\n",
    "    1. Adaboost Boosting Algorithm\n",
    "    2. Grading Boosting Algorithm\n",
    "    3. Xg Boosting Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f69dbd-e67f-4aca-8334-778a598e3a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723c185c-daa2-4118-b87c-e1f4edfea872",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q5. What are the benefits of using ensemble techniques?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67adec22-cc3c-4cac-b6df-9f70ef5fdc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans.\n",
    "Ensemble technique is perform by using its various algorithms such as adaboost, grading boosting, Xg boosting, Random \n",
    "forest classification. It doing bootstrap aggregation process, and do voting classifier and make final outputs.\n",
    "\n",
    "Benefits of ensemble techniques:\n",
    "    \n",
    "1. The benefits of ensemble techniques is that it make a single model which are form by combinations of multiple models\n",
    "    which give more accurate prediction than a simple single model.\n",
    "    \n",
    "2. By using ensemble techniques, We can increase performance and accuracy of model. Especially for complex and noisy \n",
    "    models.\n",
    "\n",
    "3. Ensemble is also helps in reducing underfitting and overfitting problem in models, by decreasing variance of models\n",
    "    which helps in get rid from overfitting.\n",
    "    \n",
    "4. Ensemble technique can handle more than one type of data like classification data, regression data, dataset having\n",
    "    outliers, dataset having too much noise,etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd17d8f-bf0d-4c6c-9dab-628fca354429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836a189b-51d3-46bb-9b97-8dce6db2eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q6. Are ensemble techniques always better than individual models?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d74930-24fe-4ca9-8569-5dc0d1a45be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans.\n",
    "Its already seen that ensemble technique is always helpful in case of performing better model or making a good accuracy\n",
    "model. In case of accuracy and performance ensemble technique is always wins in front of individual models. \n",
    "\n",
    "Because a individual models is doing all work itself its defined power will always remains in limit at a point but when \n",
    "compare to ensemble models they always perform better than a individual model because ensemble technique combines such\n",
    "individual model into a strong single model or We can also say that it combines the power of multiple model to a single \n",
    "model which results give good accuracy and perform better than a individual model.\n",
    "Above process of combining the weak models to stronger models can be done by using algorithms of ensemble technique such \n",
    "as adaboost, grading boost, Xgboost are types of algorithms of boosting and Random forest classifier is a type of bagging\n",
    "technique. \n",
    "\n",
    "Apart from this, ensemble techniques also helps in case of overfitting. A single decision tree model is spread its\n",
    "information tree until it gets leaf node and results in its get overfitted but when using ensemble techniques it uses \n",
    "multiple decision trees model parallely or in sequencely and prevent the model from overfitting case. \n",
    "Generally In overfitting case the bias is low and variance is high which is the main reason of overfitting problem and \n",
    "ensemble technique reduce the high variance to low variance and convert defect model to generalized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1ce3e-c767-4dc4-a0f5-b739172893d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2230197-7407-4039-a73e-0ddc71ba806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q7. How is the confidence interval calculated using bootstrap?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e56f793-8022-409f-8e66-870ce831a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans.\n",
    "Bootstrap is a sampling technique from which we can creates subset or samples from original data with replacement and \n",
    "calculate the population parameters like mean, standard deviations,etc.\n",
    "\n",
    "We can find confidence interval using bootstrap sampling performing through python code and numpy library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "351440e9-900f-4bae-8d8c-ebe6b042ea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47bace56-226d-4ef2-a5e8-cd6107d6d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a62a81d1-0c42-49b5-a7eb-2e338af7d5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [12,23,34,45,56,67,78,89,90,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23e65ff9-4860-46f6-8afb-799c0c0ce624",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_means = np.zeros(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7d31b62-85e1-447f-964c-e747936d28ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_samples):\n",
    "    bootstrap_samples = np.random.choice(data, size=len(data), replace=True)\n",
    "    bootstrap_mean = np.mean(bootstrap_samples)\n",
    "    bootstrap_means[i] = bootstrap_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb32e1ec-53bb-475d-bd7c-ff16f37a7246",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval = np.percentile(bootstrap_means, [1.3,99.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "012e0abb-4ce3-4999-9d9e-07bbb391e39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence interval : [30.8987 77.0056]\n"
     ]
    }
   ],
   "source": [
    "print('Confidence interval : {}'.format(confidence_interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e429ed-c5e1-4c0e-b3be-8504faa1375c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa202338-c956-4a37-9b80-1f37ab6f045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q8. How does bootstrap work and What are the steps involved in bootstrap?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534517f2-4f85-42ed-8d89-8345a537b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans.\n",
    "\n",
    "# Definition\n",
    "In statistics, Bootstrap is a resampling technique in which it take the subsets or samples of main data with replacement\n",
    "and calculate the population parameters like mean, confidence interval, standard deviations,etc. \n",
    "\n",
    "# use of bootstrap\n",
    "The bootstraping technique is needed well in case of we need to find the mean or other parameter of huge dataset. Suppose\n",
    "we need to find the mean age of 1000 employees of in a company. But it is hard to find the mean of such huge no. employees\n",
    "so for this problem we take a sample of huge data and try to find mean from sample\n",
    "\n",
    "# Steps for performing bootstrap:\n",
    "Suppose we need to find the mean of ages of 1000 employees in a company then\n",
    "\n",
    "Step-1 : Import numpy library with alias and took age samples of 10 employees in company.\n",
    "Step-2 : Assigning the total no. of employees of company\n",
    "Step-3 : Making array of all employees in company for findinf their mean value\n",
    "Step-4 : Using for loop and making bootstrap samples from np.random.choice function in numpy library.\n",
    "Step-5 : Calculating the bootstraping mean of bootstrap samples\n",
    "Step-6 : Now, applying mean for all employees in company \n",
    "Step-7 : Finding the mean of all the employees in a company and print the estimated mean variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea627586-9fee-4868-8052-b9bce551a288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated age mean of 1000 employees is : 35.265800000000006\n"
     ]
    }
   ],
   "source": [
    "#importing library with alias\n",
    "import numpy as np\n",
    "\n",
    "# age samples\n",
    "age = [21,23,45,12,67,43,32,24,35,51]\n",
    "\n",
    "# assigning total employees \n",
    "n_samples = 1000\n",
    "\n",
    "#making array of total employees\n",
    "bootstrap_means = np.zeros(n_samples)\n",
    "\n",
    "# run for loop for each employee in total emplyees\n",
    "for i in range(n_samples):\n",
    "    \n",
    "    #making bootstrap_samples from age samples\n",
    "    bootstrap_sample = np.random.choice(age, size=len(age), replace=True)\n",
    "    \n",
    "    #calculating mean of bootstrap sample\n",
    "    bootstrap_mean = np.mean(bootstrap_sample)\n",
    "    \n",
    "    #applying bootstrap mean for all employees in company\n",
    "    bootstrap_means[i] = bootstrap_mean\n",
    "    \n",
    "#calculating mean of whole emplyees\n",
    "estimated_mean = np.mean(bootstrap_means)\n",
    "\n",
    "# printing mean\n",
    "print('Estimated age mean of 1000 employees is : {}'.format(estimated_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd08ed0-5a4d-4391-9c66-382ead3141e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d83b273-718a-48f3-b9e8-1bb234a15197",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q9. A researcher wants to estimate the mean height of a population of trees. They measure the height of a sample of 50\n",
    "       trees and obtain a mean height of 15 meters and a standard deviation of 2 meters. Use bootstrap to estimate the \n",
    "       95% confidence interval for the population mean height.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "120bd14b-1f06-44e1-9018-97eed964080a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data of trees : [18.52810469 15.80031442 16.95747597 19.4817864  18.73511598 13.04544424\n",
      " 16.90017684 14.69728558 14.7935623  15.821197   15.28808714 17.90854701\n",
      " 16.52207545 15.24335003 15.88772647 15.66734865 17.98815815 14.58968347\n",
      " 15.6261354  13.29180852  9.89402037 16.30723719 16.7288724  13.51566996\n",
      " 19.53950925 12.09126865 15.09151703 14.6256323  18.06555843 17.93871754\n",
      " 15.30989485 15.75632504 13.2244285  11.03840706 14.3041757  15.31269794\n",
      " 17.46058136 17.4047597  14.22534637 14.3953945  12.90289407 12.15996413\n",
      " 11.58745962 18.90155079 13.98069564 14.1238514  12.49440928 16.55498071\n",
      " 11.7722043  14.57451944]\n"
     ]
    }
   ],
   "source": [
    "#Ans.\n",
    "\n",
    "#numpy_library\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "#Sample_data\n",
    "sample_size = 50  \n",
    "sample_mean = 15 \n",
    "sample_std = 2   \n",
    "\n",
    "#Making sample data\n",
    "Sample_data = np.random.normal(loc=sample_mean, scale=sample_std, size=sample_size)\n",
    "\n",
    "#printing\n",
    "print('Sample data of trees : {}'.format(Sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33cad091-5fce-45b8-bf61-531d1ebb4ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval for Mean Height (meters): [14.63356151 15.89649357]\n"
     ]
    }
   ],
   "source": [
    "# Number of bootstrap samples\n",
    "num_bootstrap_samples = 1000\n",
    "\n",
    "# Generate bootstrap samples\n",
    "bootstrap_means = []\n",
    "\n",
    "for i in range(num_bootstrap_samples):\n",
    "    # Resample with replacement from the original sample\n",
    "    resampled_data = np.random.choice(Sample_data, size=sample_size, replace=True)\n",
    "    \n",
    "    # Calculate the mean of the bootstrap sample\n",
    "    bootstrap_mean = np.mean(resampled_data)\n",
    "    bootstrap_means.append(bootstrap_mean)\n",
    "\n",
    "# Calculate the 95% confidence interval\n",
    "confidence_interval = np.percentile(bootstrap_means, [2.5, 97.5])\n",
    "\n",
    "# Print the confidence interval\n",
    "print(\"95% Confidence Interval for Mean Height (meters):\", confidence_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e711be-4798-4c7c-9e3a-c050698f7d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f81af-391b-481b-9a39-5d6b118359bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "                     ◦•●◉✿ ❤️️' 𝐉 𝐀 𝐈   𝐒 𝐇 𝐑 𝐄 𝐄   𝐇 𝐀 𝐑 𝐈   𝐕 𝐈 𝐒 𝐇 𝐍 𝐔 '❤️ ✿◉●•◦"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
